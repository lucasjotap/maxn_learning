# Personalized Recommendation Engine + Automation Layer

A production-ready ML engineering system for personalized recommendations with real-time automation through n8n integration.

## Overview

This system combines multiple recommendation algorithms (KNN, Collaborative Filtering, Embeddings) with automated workflows to deliver personalized content recommendations across multiple domains (movies, music, tasks, notes).

### Key Features

- **Multiple ML Models**: KNN-based collaborative filtering, matrix factorization (ALS/BPR), and semantic embeddings
- **Data Warehouse**: DuckDB-based warehouse for scalable data storage and retrieval
- **Behavior Tracking**: Comprehensive user interaction logging and analysis
- **Automation Layer**: n8n workflows for automated recommendation delivery
- **Auto-Retraining**: Scheduled model retraining based on new user interactions
- **REST API**: FastAPI-based API for easy integration with n8n and other services

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   n8n Workflows â”‚
â”‚  (Automation)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ HTTP API
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI Serverâ”‚
â”‚  (REST API)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Behavior â”‚ â”‚Recommendation    â”‚
â”‚Tracker  â”‚ â”‚Engine            â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚               â”‚
     â”‚               â”‚
     â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Data Warehouse        â”‚
â”‚    (DuckDB)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start (See It In Action!)

The fastest way to see the system in action:

```bash
# Make quickstart script executable
chmod +x quickstart.sh

# Run the quickstart (installs deps, seeds data, trains models, starts server)
./quickstart.sh
```

This will:
1. âœ… Set up virtual environment and install dependencies
2. âœ… Seed sample data (users, movies, music, tasks)
3. âœ… Train all ML models
4. âœ… Start the API server at http://localhost:8000

Then in **another terminal**:

```bash
# Run the demo to see recommendations in action
python demo.py

# Or test the API endpoints
chmod +x test_api.sh
./test_api.sh

# Or visit the interactive API docs
open http://localhost:8000/docs
```

### Quick Demo Script

```bash
# Run the interactive demo
python demo.py
```

This shows:
- User statistics
- Movie recommendations
- Music recommendations  
- Task prioritization
- Semantic search example

## Installation

### Prerequisites

- Python 3.8+
- n8n (for automation workflows - optional)

### Manual Setup

1. **Clone the repository**:
```bash
git clone <repo-url>
cd mxn_learning
```

2. **Install dependencies**:
```bash
pip install -r requirements.txt
```

3. **Seed sample data**:
```bash
python -m src.seed_data
```

4. **Train initial models**:
```bash
python -m src.main --mode training
```

Or use the API:
```bash
curl -X POST http://localhost:8000/training/train
```

5. **Start the API server**:
```bash
python -m src.main --mode api
```

Or both API and training pipeline:
```bash
python -m src.main --mode both
```

## Usage

### API Endpoints

#### User Interactions

**Log interaction**:
```bash
POST /interactions
{
  "user_id": "user1",
  "domain": "movies",
  "item_id": "movie_1",
  "interaction_type": "like",
  "rating": 5.0
}
```

**Bulk log interactions**:
```bash
POST /interactions/bulk
{
  "interactions": [...]
}
```

#### Recommendations

**Get personalized recommendations**:
```bash
POST /recommendations
{
  "user_id": "user1",
  "domain": "movies",
  "top_k": 10,
  "model_types": ["knn", "collab", "embedding"],
  "query_text": "sci-fi action movies"
}
```

**Get daily playlist**:
```bash
GET /automation/daily-playlist/{user_id}
```

**Get weekly movies**:
```bash
GET /automation/weekly-movies/{user_id}
```

**Get task prioritization**:
```bash
GET /automation/task-prioritization/{user_id}
```

#### Training

**Trigger model training**:
```bash
POST /training/train?domain=movies
```

**Get training statistics**:
```bash
GET /training/stats?domain=movies
```

### n8n Integration

1. **Import workflows**:
   - Import JSON files from `n8n/` directory into your n8n instance
   - Configure environment variables:
     - `USER_ID`: Default user ID for recommendations
     - `MUSIC_SERVICE_WEBHOOK`: Webhook URL for music service
     - `MOVIE_SERVICE_WEBHOOK`: Webhook URL for movie service
     - `TASK_SERVICE_WEBHOOK`: Webhook URL for task service
     - `NOTIFICATION_SERVICE_WEBHOOK`: Webhook URL for notifications

2. **Available workflows**:
   - `daily-playlist-workflow.json`: Daily music playlist generation
   - `weekly-movies-workflow.json`: Weekly movie recommendations
   - `task-prioritization-workflow.json`: Daily task prioritization
   - `auto-retraining-workflow.json`: Automated model retraining

### Python API

```python
from src.recommendation_engine import RecommendationEngine
from src.behavior_tracker import BehaviorTracker

# Initialize
engine = RecommendationEngine()
tracker = BehaviorTracker(engine.warehouse)

# Track behavior
tracker.track_like(
    user_id="user1",
    domain="movies",
    item_id="movie_1",
    rating=5.0
)

# Get recommendations
recommendations = engine.recommend(
    user_id="user1",
    domain="movies",
    top_k=10
)

# Train models
engine.train_all_models("movies")
```

## Model Details

### 1. KNN Recommender
- **Type**: Item-based collaborative filtering
- **Algorithm**: k-Nearest Neighbors with cosine/euclidean distance
- **Use Case**: Similar item recommendations based on user-item matrix

### 2. Collaborative Filtering
- **Type**: Matrix factorization
- **Algorithm**: Alternating Least Squares (ALS) or Bayesian Personalized Ranking (BPR)
- **Use Case**: Personalized recommendations based on user-item interactions

### 3. Embedding Recommender
- **Type**: Semantic embeddings
- **Algorithm**: Sentence Transformers (all-MiniLM-L6-v2 by default)
- **Use Case**: Content-based recommendations using text descriptions

### Ensemble Strategy
The system combines recommendations from all available models using weighted averaging to provide robust, diverse recommendations.

## Configuration

Edit `config/config.yaml` to customize:

- **Domains**: Enable/disable domains and configure model parameters
- **API**: Server host and port
- **Training**: Retraining intervals and minimum samples
- **Automation**: Schedule and top-k settings for automated workflows

## Data Warehouse Schema

The system uses DuckDB with the following tables:

- `user_interactions`: All user interactions with items
- `users`: User metadata
- `items_catalog`: Item catalog with metadata and embeddings
- `recommendations`: Cached recommendations
- `training_history`: Model training logs and metrics

## Development

### Running Tests

```bash
pytest tests/
```

### Code Structure

```
mxn_learning/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # Main entry point
â”‚   â”œâ”€â”€ api_server.py              # FastAPI server
â”‚   â”œâ”€â”€ recommendation_engine.py   # Unified recommendation engine
â”‚   â”œâ”€â”€ behavior_tracker.py        # User behavior tracking
â”‚   â”œâ”€â”€ data_warehouse.py          # DuckDB data warehouse
â”‚   â”œâ”€â”€ training_pipeline.py       # Auto-retraining pipeline
â”‚   â”œâ”€â”€ seed_data.py               # Sample data generator
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ knn_recommender.py
â”‚       â”œâ”€â”€ collaborative_filtering.py
â”‚       â””â”€â”€ embedding_recommender.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                # Configuration file
â”œâ”€â”€ n8n/
â”‚   â”œâ”€â”€ daily-playlist-workflow.json
â”‚   â”œâ”€â”€ weekly-movies-workflow.json
â”‚   â”œâ”€â”€ task-prioritization-workflow.json
â”‚   â””â”€â”€ auto-retraining-workflow.json
â”œâ”€â”€ models/                        # Trained models (gitignored)
â”œâ”€â”€ data/                          # Data warehouse (gitignored)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Production Considerations

1. **Model Storage**: Trained models are saved to `models/` directory. Consider using cloud storage for production.

2. **Data Warehouse**: DuckDB is file-based. For production, consider PostgreSQL or cloud data warehouses.

3. **API Security**: Add authentication/authorization for production deployment.

4. **Monitoring**: Add logging and metrics collection for production monitoring.

5. **Scaling**: Consider horizontal scaling with multiple API instances behind a load balancer.

6. **Model Versioning**: Implement model versioning and A/B testing for production.

## License

MIT License

## Contributing

Contributions welcome! Please open an issue or submit a pull request.
